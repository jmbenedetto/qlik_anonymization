{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "3b2d257a6a32433f891e644882cd931e",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "# GOAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "37e826188d1847038a7e051cc5d9b7c5",
    "deepnote_cell_height": 327,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Anonymize data from AR app to allow public sharing.\n",
    "- AR Comments (OK)\n",
    "- Countries (N/A)\n",
    "- DSO (OK)\n",
    "- ExchangeRates (N/A)\n",
    "- Invoice Item Detail\n",
    "- Invoices (OK)\n",
    "- Items (OK)\n",
    "- Link Table (N/A)\n",
    "- Product Lines (OK)\n",
    "- Subsidiaries (OK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f20b6be1f02a4133a48c0c2ef135e292",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "# PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "4848431b-5825-47f5-8df6-079660b7c9d1",
    "deepnote_cell_height": 190,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     611
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9006,
    "execution_start": 1658855463630,
    "source_hash": "3a70f3ff",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from anonympy.pandas import dfAnonymizer\n",
    "from anonympy.pandas.utils_pandas import available_methods\n",
    "from anonympy.pandas.utils_pandas import fake_methods\n",
    "import os\n",
    "import gcsfs\n",
    "import pickle\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ddf09dbcf2d0456dbaa2074da9b1c430",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "# PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "44e68c69783b48abb78fdd9ee552df9b",
    "deepnote_cell_height": 81,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1658855472644,
    "source_hash": "b87bc622",
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '../secrets/gcp_qlik_key.json'\n",
    "source_path='gs://qlik-demos-data/finance/in/'\n",
    "destination_path='gs://qlik-demos-data/finance/out/'\n",
    "pd_options = {\"token\": os.environ['GOOGLE_APPLICATION_CREDENTIALS']}\n",
    "fs = gcsfs.GCSFileSystem(token=os.environ['GOOGLE_APPLICATION_CREDENTIALS'])\n",
    "\n",
    "# seeds and keys for anonymization\n",
    "key = 'qlikrulesaboveallothers'\n",
    "seed = 1001\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# files\n",
    "    \n",
    "dict_files = {\n",
    "    'Countries': 'AR_Countries V1',\n",
    "    \"Invoice Item Detail\":\"AR_Invoice Item Detail V1\",\n",
    "    \"Product Lines\": \"AR_Product Lines V1\",\n",
    "    \"Invoices\": \"AR_Invoices V1\",\n",
    "    \"Items\":\"AR_Items V1\",\n",
    "    \"Comments\":\"AR_Comments V1\",\n",
    "    \"DSO\":\"AR_DSO V1\",\n",
    "    \"Link Table\":\"AR_Link Table V1\",\n",
    "    \"Subsidiaries\":\"AR_Subsidiaries V1\",\n",
    "    \"ExchangeRates\":\"AR_ExchangeRates V1\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "45bbce8291b042a8bf67cf4e389f74ce",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## noise_amount_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "21f9c6f879ad487bb349228d637d3f80",
    "deepnote_cell_height": 117,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1658868016416,
    "source_hash": "217a00e4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def noise_amount_column(original_column):\n",
    "    noise_column=original_column.replace(\".-\",\"-0.\",regex=True).astype('float')\n",
    "    return noise_column.apply(lambda x: round(x*2/3+50000,1) if x>=0 else round(x*2/3-50000,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scramble_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scramble_column(original_column):\n",
    "    scrambled_column=original_column.copy()\n",
    "    def scramble_str(original_str):\n",
    "        def return_number(number=0.3):\n",
    "            return number\n",
    "        \n",
    "        scrambled_str=list(original_str)\n",
    "        shuffle(scrambled_str,return_number)\n",
    "\n",
    "        return \"\".join([str(item) for item in scrambled_str])\n",
    "    return scrambled_column.apply(scramble_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sequential_values_for_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequencial_values_for_column(original_column):\n",
    "    columns_names={'index':'new',0:'original'}\n",
    "    sequencial_values_for_column=pd.DataFrame(set(original_column)).reset_index().rename(columns=columns_names)\n",
    "    sequencial_values_for_column=pd.merge(\n",
    "        original_column,\n",
    "        sequencial_values_for_column,\n",
    "        left_on=original_column.name,\n",
    "        right_on='original',\n",
    "        how='left').drop(\n",
    "            columns=['original',original_column.name])\n",
    "    return sequencial_values_for_column.rename(columns={'new':original_column.name})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fake_data_for_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_data_for_column(original_column,fake_method):\n",
    "\n",
    "    # create a 2 columns dataframe with the unique values from original_column twice\n",
    "    df_exclusive_values=original_column.drop_duplicates()\n",
    "    df_exclusive_values=pd.merge(df_exclusive_values,df_exclusive_values,how='inner',left_index=True,right_index=True,suffixes=('','_fake'))\n",
    "\n",
    "    anon_exclusive_values=dfAnonymizer(df_exclusive_values)\n",
    "    anon_exclusive_values.categorical_fake({original_column.name+'_fake':fake_method},seed=seed)\n",
    "    \n",
    "    fake_data_for_column=pd.merge(original_column,\n",
    "        anon_exclusive_values.to_df(),\n",
    "        how='left',\n",
    "        on=original_column.name\n",
    "        ).drop(columns=[original_column.name])\n",
    "    return fake_data_for_column.rename(columns={original_column.name+'_fake':original_column.name})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6e21545b374a4ce8b0b3a19a256cd8b8",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "# DATA ANONYMIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "20c3069446a646cfb370a4470bfba72e",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## Subsidiaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "4fb75aff41f440638a1768b31cbb3d75",
    "deepnote_cell_height": 446,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 894,
    "execution_start": 1658856986271,
    "source_hash": "d2026652",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read original file from gcs\n",
    "df_subsidiaries=pd.read_csv(source_path+dict_files['Subsidiaries']+'.csv',storage_options=pd_options)\n",
    "df_subsidiaries['NetSuite Subsidiary ID']=df_subsidiaries['NetSuite Subsidiary ID'].astype('str')\n",
    "\n",
    "print('original dataframe')\n",
    "display(df_subsidiaries.head())\n",
    "\n",
    "# anonymize dataframe\n",
    "anon_subsidiaries = dfAnonymizer(df_subsidiaries)\n",
    "\n",
    "# anon_subsidiaries.categorical_tokenization('%SubsidiaryCode',max_token_len=3,key=key)\n",
    "anon_subsidiaries.categorical_fake({'Subsidiary':'company'},seed=seed)\n",
    "anon_subsidiaries.column_suppression(['Is Attunity Subsidiary','VAT Registration Number'])\n",
    "anon_subsidiaries.categorical_resampling(\n",
    "    ['Subsidiary Currency Code','Subsidiary Region'],seed=seed)\n",
    "\n",
    "print(anon_subsidiaries.info())\n",
    "\n",
    "df_subsidiaries_anon=anon_subsidiaries.to_df()\n",
    "df_subsidiaries_anon['NetSuite Subsidiary ID']=df_subsidiaries_anon['%SubsidiaryCode']\n",
    "df_subsidiaries_anon['Subsidiary Legal Name']=df_subsidiaries_anon['Subsidiary']\n",
    "df_subsidiaries_anon['Workday Subsidiary Name']=df_subsidiaries_anon['Subsidiary']\n",
    "df_subsidiaries_anon['Subsidiary Region']=df_subsidiaries_anon['Subsidiary Region'].replace({'Technologies':'World'},inplace=False)\n",
    "\n",
    "# merge original and anonymized dataframes\n",
    "df_subsidiaries=df_subsidiaries.join(df_subsidiaries_anon,how='inner',lsuffix='_orig')\n",
    "print('full dataframe')\n",
    "display(df_subsidiaries.head())\n",
    "\n",
    "# persist anonymized df to GCS\n",
    "df_subsidiaries_anon.to_csv(destination_path+dict_files['Subsidiaries']+'.csv',index=False)\n",
    "\n",
    "# persist mapping tables to GCS\n",
    "# map_subsidiary_code = dict(zip(df_subsidiaries['%SubsidiaryCode_orig'], df_subsidiaries['%SubsidiaryCode']))\n",
    "map_subsidiary_currency_code = dict(zip(df_subsidiaries['Subsidiary Currency Code_orig'], df_subsidiaries['Subsidiary Currency Code']))\n",
    "\n",
    "# with fs.open(destination_path+'map_subsidiary_code.pickle', 'wb') as handle:\n",
    "#     pickle.dump(map_subsidiary_code, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with fs.open(destination_path+'map_subsidiary_currency_code.pickle', 'wb') as handle:\n",
    "    pickle.dump(map_subsidiary_currency_code, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "df_subsidiaries = anon_subsidiaries=df_subsidiaries_anon=map_subsidiary_code=map_subsidiary_currency_code=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8d028d302f8e42218c6e022d56c7d8f6",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## AR Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "ca58cf872b374a0aaa222f06f1f768fb",
    "deepnote_cell_height": 449,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1253,
    "execution_start": 1658826136106,
    "source_hash": "76513b78",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read original file from gcs\n",
    "df_comments = pd.read_csv(source_path+dict_files['Comments']+'.csv',storage_options=pd_options)\n",
    "#df_comments[['comment_date','comment_text']]=df_comments['%ARCommentKey'].str.split('|',expand=True,n=1)\n",
    "#df_comments['comment_date']=pd.to_datetime(df_comments['comment_date']).dt.date\n",
    "print('original dataframe')\n",
    "display(df_comments.head())\n",
    "\n",
    "# anonymize dataframe\n",
    "anon_comments=dfAnonymizer(df_comments)\n",
    "#anon_comments.column_suppression(['comment_text'])\n",
    "anon_comments.categorical_tokenization(['%ARCommentKey'],max_token_len=10,key=key)\n",
    "#anon_comments.datetime_noise('comment_date',seed=seed)\n",
    "\n",
    "df_comments_anon=anon_comments.to_df()\n",
    "df_comments_anon['AR Comments']=df_comments_anon['AR Comments'].apply(lambda x:0 if pd.isna(x) else 1)\n",
    "\n",
    "anon_comments.info()\n",
    "\n",
    "df_comments=df_comments.join(df_comments_anon,how='inner',lsuffix='_orig')\n",
    "print('full dataframe')\n",
    "display(df_comments.head())\n",
    "\n",
    "#persist anonymized df to GCS\n",
    "df_comments_anon.to_csv(destination_path+dict_files['Comments']+'.csv',index=False)\n",
    "\n",
    "# persist mapping tables to GCS\n",
    "map_comment_key = dict(zip(df_comments['%ARCommentKey_orig'], df_comments['%ARCommentKey']))\n",
    "with fs.open(destination_path+'map_comment_key.pickle', 'wb') as handle:\n",
    "    pickle.dump(map_comment_key, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "df_comments=df_comments_anon=map_comment_key=[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bd2c184cc4724acb8fcfc66645fe7359",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## DSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "423aeae999d44af2a9b057d4af26e88b",
    "deepnote_cell_height": 482,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 354,
    "execution_start": 1658866526326,
    "source_hash": "5166c842",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read original file from gcs\n",
    "df_dso = pd.read_csv(source_path+dict_files['DSO']+'.csv')\n",
    "#df_dso['NetSuite Extract DateTime']=pd.to_datetime(df_dso['NetSuite Extract DateTime'])\n",
    "\n",
    "# split '%DSOKey' in period and subsidiary code to apply different anonymization\n",
    "# df_dso[['period','subsidiary_code']]=df_dso['%DSOKey'].str.split('|',expand=True)\n",
    "#df_dso['period']=pd.to_datetime(df_dso['period'])\n",
    "\n",
    "print('original dataframe')\n",
    "display(df_dso.head())\n",
    "\n",
    "# read mapping tables from gcs\n",
    "\n",
    "# with fs.open(destination_path+'map_subsidiary_code.pickle', 'rb') as handle:\n",
    "#     map_subsidiary_code = pickle.load(handle)\n",
    "with fs.open(destination_path+'map_subsidiary_currency_code.pickle', 'rb') as handle:\n",
    "    map_subsidiary_currency_code = pickle.load(handle)\n",
    "\n",
    "# anonymize dataframe\n",
    "anon_dso=dfAnonymizer(df_dso)\n",
    "#anon_dso.datetime_noise(['NetSuite Extract DateTime','period'],seed=seed)\n",
    "anon_dso.info()\n",
    "\n",
    "df_dso_anon=anon_dso.to_df()\n",
    "df_dso_anon['Transaction Line Amount - Local']=noise_amount_column(\n",
    "    df_dso_anon['Transaction Line Amount - Local'])\n",
    "df_dso_anon['Transaction Line Amount - USD']=noise_amount_column(\n",
    "    df_dso_anon['Transaction Line Amount - USD'])\n",
    "# df_dso_anon['%DSOKey']=df_dso_anon[\n",
    "#     'period'].dt.strftime(\"%Y-%m\")+'|'+df_dso_anon['subsidiary_code'].map(map_subsidiary_code)\n",
    "# df_dso_anon['From Currency Code']=df_dso_anon['From Currency Code'].map(map_subsidiary_currency_code)\n",
    "# df_dso_anon['%DSOKey']=df_dso_anon[\n",
    "#     'period']+'|'+df_dso_anon['subsidiary_code'].map(map_subsidiary_code)\n",
    "df_dso_anon['From Currency Code']=df_dso_anon['From Currency Code'].map(map_subsidiary_currency_code)\n",
    "\n",
    "\n",
    "\n",
    "# merge original and anonymized dataframes\n",
    "df_dso=df_dso.join(df_dso_anon,how='inner',lsuffix='_orig')\n",
    "print('full dataframe')\n",
    "display(df_dso.head())\n",
    "\n",
    "# persist anonymized df to GCS\n",
    "df_dso_anon.to_csv(destination_path+dict_files['DSO']+'.csv',index=False)\n",
    "\n",
    "# persist mapping tables to GCS\n",
    "# map_dso_key = dict(zip(df_dso['%DSOKey_orig'], df_dso['%DSOKey']))\n",
    "# with fs.open(destination_path+'map_dso_key.pickle', 'wb') as handle:\n",
    "#     pickle.dump(map_dso_key, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# map_period=dict(zip(df_dso['period_orig'], df_dso['period']))\n",
    "# with fs.open(destination_path+'map_period.pickle', 'wb') as handle:\n",
    "#     pickle.dump(map_period, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# drop artificial columns created by splitting '%DSOKey'\n",
    "# df_dso=df_dso.drop(columns=['period','subsidiary_code','period_orig','subsidiary_code_orig'])\n",
    "# df_dso_anon=df_dso_anon.drop(columns=['period','subsidiary_code'])\n",
    "\n",
    "df_dso=df_dso_anon=anon_dso=map_subsidiary_code=map_subsidiary_currency_code=map_dso_key=map_period=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6deb9e012f1c465f82e7410025143b7d",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## Invoices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "4778789035634521943c48b3b21fb425",
    "deepnote_cell_height": 552,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2798,
    "execution_start": 1658867292400,
    "source_hash": "189d74b1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read original file from gcs\n",
    "df_invoice = pd.read_csv(source_path+dict_files['Invoices']+'.csv',low_memory=False)\n",
    "# date_columns=['Date','Due Date','As Of Date','Rev. Rec. Start Date','Rev. Rec. End Date','Contract Item Start Date','Contract Item End Date']\n",
    "#for column in date_columns:\n",
    "#    df_invoice[column]=pd.to_datetime(df_invoice[column],errors='coerce')\n",
    "\n",
    "string_columns=['Customer Code','PO Number','%ItemID']\n",
    "for column in string_columns:\n",
    "    df_invoice[column]=df_invoice[column].astype(str)\n",
    "\n",
    "# create 2 columns to store the original values of the columns to be anonymized\n",
    "# df_invoice[['document_id','item_id']]=df_invoice['%InvoiceItemKey'].str.split('|',expand=True,n=1)\n",
    "\n",
    "print('original dataframe: ',df_invoice.shape)\n",
    "display(df_invoice.head())\n",
    "\n",
    "# read mapping tables from gcs\n",
    "with fs.open(destination_path+'map_subsidiary_currency_code.pickle', 'rb') as handle:\n",
    "    map_subsidiary_currency_code = pickle.load(handle)\n",
    "# with fs.open(destination_path+'map_subsidiary_code.pickle', 'rb') as handle:\n",
    "#     map_subsidiary_code = pickle.load(handle)\n",
    "with fs.open(destination_path+'map_comment_key.pickle', 'rb') as handle:\n",
    "    map_comment_key = pickle.load(handle)\n",
    "# with fs.open(destination_path+'map_dso_key.pickle', 'rb') as handle:\n",
    "#     map_dso_key = pickle.load(handle)\n",
    "\n",
    "\n",
    "# anonymize dataframe\n",
    "anon_invoice=dfAnonymizer(df_invoice)\n",
    "anon_invoice.column_suppression(['Detail URL','Customer URL','%SummaryKey','Project Name','Credit Limit'])\n",
    "# anon_invoice.datetime_noise(date_columns,seed=seed)\n",
    "\n",
    "anon_invoice.categorical_tokenization(['PO Number'],max_token_len=10,key=key)\n",
    "anon_invoice.categorical_resampling(['Country Code'],seed=seed)\n",
    "anon_invoice.info()\n",
    "\n",
    "df_invoice_anon=anon_invoice.to_df()\n",
    "value_columns=[\n",
    "    'Temp Transaction Amount',\n",
    "    'Temp Amount Due (Foreign Currency)',\n",
    "    'Open Balance',\n",
    "    'Amount Due (Foreign Currency)',\n",
    "    'Transaction Amount',\n",
    "    'Remaining (m)',\n",
    "    'Recognized Balance',\n",
    "    'Remaining Deferred Balance',\n",
    "    'Tax Value',\n",
    "    'Recognized Balance (Foreign Currency)',\n",
    "    'Remaining Deferred Balance (Foreign Currency)',\n",
    "    'Tax Value (Foreign Currency)',\n",
    "    'Recognized Balance (Local)',\n",
    "    'Remaining Deferred Balance (Local)',\n",
    "    'Tax Value (Local)'\n",
    "    ]\n",
    "for column in value_columns:\n",
    "    df_invoice_anon[column]=noise_amount_column(df_invoice_anon[column])\n",
    "\n",
    "# create fake data\n",
    "df_invoice_anon['Customer Name']=fake_data_for_column(df_invoice_anon['Customer Name'],'company')\n",
    "# df_invoice_anon['Sales Rep Name']=fake_data_for_column(df_invoice_anon['Sales Rep Name'],'name')\n",
    "df_invoice_anon['Accounts Receivable Accountant']=fake_data_for_column(df_invoice_anon['Accounts Receivable Accountant'],'name')\n",
    "\n",
    "# # anonymize %InvoiceItemKey and delete support fields\n",
    "# df_invoice_anon['%InvoiceItemKey']=df_invoice_anon['document_id'].astype(str)+'|'+df_invoice_anon['item_id'].astype(str)\n",
    "# df_invoice_anon=df_invoice_anon.drop(columns=['document_id','item_id'])\n",
    "# df_invoice=df_invoice.drop(columns=['document_id','item_id'])\n",
    "\n",
    "# replace values with mapped values\n",
    "df_invoice_anon['Transaction Currency']=df_invoice_anon['Transaction Currency'].map(map_subsidiary_currency_code)\n",
    "df_invoice_anon['%ARCommentKey']=df_invoice_anon['%ARCommentKey'].map(map_comment_key)\n",
    "# df_invoice_anon['%DSOKey']=df_invoice_anon['%DSOKey'].map(map_dso_key)\n",
    "\n",
    "# scramble values in 'Customer Code' and 'End User Code'\n",
    "df_invoice_anon['Customer Code']=scramble_column(df_invoice_anon['Customer Code'].astype('str'))\n",
    "df_invoice_anon['End User Code']=scramble_column(df_invoice_anon['End User Code'].astype('str'))\n",
    "df_invoice_anon['Customer Original']=df_invoice_anon['Customer Code']+' '+df_invoice_anon['Customer Name']\n",
    "\n",
    "# inherit values from other fields\n",
    "df_invoice_anon['Customer']=df_invoice_anon['Customer Original']\n",
    "df_invoice_anon['End User']=df_invoice_anon['End User Code']\n",
    "\n",
    "df_invoice=df_invoice.join(df_invoice_anon,how='inner',lsuffix='_orig')\n",
    "# display full dataframe\n",
    "print('full dataframe',df_invoice.shape)\n",
    "display(df_invoice.head())\n",
    "\n",
    "#persist anonymized df to GCS\n",
    "df_invoice_anon.to_csv(destination_path+dict_files['Invoices']+'.csv',index=False)\n",
    "print('anon dataframe',df_invoice_anon.shape)\n",
    "\n",
    "# persist mapping tables to GCS\n",
    "# map_invoice_key=dict(zip(df_invoice['%InvoiceItemKey_orig'], df_invoice['%InvoiceItemKey']))\n",
    "# with fs.open(destination_path+'map_invoice_key.pickle', 'wb') as handle:\n",
    "#     pickle.dump(map_invoice_key, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#drop variables\n",
    "map_subsidiary_currency_code=map_invoice_key=map_subsidiary_code=map_comment_key=map_dso_key=df_invoice=df_invoice_anon=anon_invoice=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load original file from gcs\n",
    "df_items=pd.read_csv(source_path+dict_files['Items']+'.csv')\n",
    "string_columns=['%ItemID']\n",
    "for column in string_columns:\n",
    "    df_items[column]=df_items[column].astype(str)\n",
    "\n",
    "display(df_items.head())\n",
    "\n",
    "# anonymize dataframe\n",
    "anon_items=dfAnonymizer(df_items)\n",
    "anon_items.categorical_resampling(\n",
    "    ['Item Type','Product Family'],seed=seed)\n",
    "\n",
    "anon_items.info()\n",
    "\n",
    "df_items_anon=anon_items.to_df()\n",
    "\n",
    "# create fake data\n",
    "categorical_fake_dict={'Item Name':'color_name','Bookings Group 1':'word','Bookings Group 2':'currency_name','Bookings Group 3':'job'}\n",
    "for key,value in categorical_fake_dict.items():\n",
    "    df_items_anon[key]=fake_data_for_column(df_items_anon[key],value)\n",
    "\n",
    "# inherit values from anonymized fields\n",
    "df_items_anon['Item Description']=df_items_anon['Item Name']\n",
    "df_items_anon['Item']=df_items_anon['Item Name']\n",
    "df_items_anon['Product Family']=df_items_anon['Product Family'].replace('Qonnect Fees','Misc',inplace=False)\n",
    "\n",
    "# merge anonymized df with original df\n",
    "df_items=df_items.join(df_items_anon,how='inner',lsuffix='_orig')\n",
    "display(df_items.head())\n",
    "\n",
    "# persist anonymized df to GCS\n",
    "df_items_anon.to_csv(destination_path+dict_files['Items']+'.csv',index=False)\n",
    "\n",
    "# drop variables\n",
    "df_items=df_items_anon=anon_items=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from GCS\n",
    "df_product_lines=pd.read_csv(source_path+dict_files['Product Lines']+'.csv')\n",
    "print('original dataframe')\n",
    "display(df_product_lines.head())\n",
    "\n",
    "# anonymize dataframe\n",
    "anon_product_lines=dfAnonymizer(df_product_lines)\n",
    "anon_product_lines.info()\n",
    "\n",
    "df_product_lines_anon=anon_product_lines.to_df()\n",
    "\n",
    "# create fake data\n",
    "categorical_fake_dict={'Product Line 3':'state','Product Line 2':'free_email_domain'}\n",
    "for key,value in categorical_fake_dict.items():\n",
    "    df_product_lines_anon[key]=fake_data_for_column(df_product_lines_anon[key],value)\n",
    "\n",
    "map_product_line1={\n",
    "    'Analytics':'Go to Market','Data Integration':'Operations','Non-Product Invoicing':'Others','Professional Services' : 'Support functions'}\n",
    "df_product_lines_anon['Product Line 1']=df_product_lines_anon['Product Line 1'].map(map_product_line1)\n",
    "\n",
    "# merge anonymized df with original df\n",
    "df_product_lines=df_product_lines.join(df_product_lines_anon,how='inner',lsuffix='_orig')\n",
    "display(df_product_lines.head())\n",
    "\n",
    "# persist anonymized df to GCS\n",
    "df_product_lines_anon.to_csv(destination_path+dict_files['Product Lines']+'.csv',index=False)\n",
    "\n",
    "# persist mapping tables to GCS\n",
    "map_product_line3=dict(zip(df_product_lines['Product Line 3_orig'], df_product_lines['Product Line 3']))\n",
    "with fs.open(destination_path+'map_product_line3.pickle', 'wb') as handle:\n",
    "    pickle.dump(map_product_line3, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "df_product_lines=df_product_lines_anon=anon_product_lines=map_product_line3=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoice Item Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from GCS\n",
    "df_invoice_item=pd.read_csv(source_path+dict_files['Invoice Item Detail']+'.csv')\n",
    "print('original dataframe')\n",
    "display(df_invoice_item.head())\n",
    "\n",
    "# read mapping tables from GCS\n",
    "# with fs.open(destination_path+'map_invoice_key.pickle', 'rb') as handle:\n",
    "#     map_invoice_key = pickle.load(handle)\n",
    "with fs.open(destination_path+'map_product_line3.pickle', 'rb') as handle:\n",
    "    map_product_line3 = pickle.load(handle)\n",
    "\n",
    "#anonymize dataframe\n",
    "anon_invoice_item=dfAnonymizer(df_invoice_item)\n",
    "anon_invoice_item.column_suppression(['Created By'])\n",
    "anon_invoice_item.info()\n",
    "\n",
    "df_invoice_item_anon=anon_invoice_item.to_df()\n",
    "\n",
    "# df_invoice_item_anon['%InvoiceItemKey']=df_invoice_item_anon['%InvoiceItemKey'].map(map_invoice_key)\n",
    "df_invoice_item_anon['Product Line 3']=df_invoice_item_anon['Product Line 3'].map(map_product_line3)\n",
    "\n",
    "# merge anonymized df with original df\n",
    "df_invoice_item=df_invoice_item.join(df_invoice_item_anon,how='inner',lsuffix='_orig')\n",
    "display(df_invoice_item.head())\n",
    "\n",
    "# persist anonymized df to GCS\n",
    "df_invoice_item_anon.to_csv(destination_path+dict_files['Invoice Item Detail']+'.csv',index=False)\n",
    "\n",
    "df_invoice_item_anon=df_invoice_item=anon_invoice_item=map_invoice_key=map_product_line3=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "9633830c-bf8c-448e-8e41-7ea81edd4ff6",
  "kernelspec": {
   "display_name": "Python 3.10.5 ('anonympy_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "aa3889c62e1481d890a595dc2af92684f237c9a72e5d33d00dfccb2a726e94c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
